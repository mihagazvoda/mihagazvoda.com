---
title: "Intuitive Bayesian updating for binomial data"
description: |
  With interactive app and example in R.
categories: 
  - data science
  - bayesian inference
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 11-24-2020
output:
  distill::distill_article:
    self_contained: false
---

I've struggled many times to dive into Bayesian inference. I attended 10+ hour course (and passed it) without properly understanding what I'm doing. Then I, while watching [the talk about linear models and using common sense](https://www.youtube.com/watch?v=68ABAU_V8qI), came across Statistical Rethinking [book](https://xcelab.net/rm/statistical-rethinking/) and [video course](https://www.youtube.com/watch?v=4WVelCswXo4). [^1]

[^1]: I think they supplement each other well. If you need to pick one, go with the book. 

While the first chapter (and a lecture) can be a bit boring I cannot recommend it enough. The author focuses that you grasp the topic without (almost any) equations but with common sense. And I started to understand what's going on. And even more importantly - I figured out that I learn by doing - not by listening. That's how this article (and a dashboard, but more on this later) was born.[^2]

[^2]: I'm at chapter 4 so don't expect too much.

## Tossing, again

The author introduces earth tossing example for approximating proportion of sea on the earth surface. You throw globe in the air, catch it, check your index finger, write down if it's sea (1 = success) or land (0 = failure). By throwing and catching it a lot of times you could estimate proportion of sea on the earth. But how sure can you be about the estimation?

Let's say `p` is probability of success, i.e. probability that we will catch the earth pointing on sea which translates into proportion of earth's surface covered by the sea. Based on tossing outcomes we will estimate how likely is that each of that `p` could generate such data. By each `p` I mean all probabilities of success, from 0 to 1. ^[To keep things simpler one can focus on each tenth percent.]

## Priors

In Bayesian world, there's no only data (it could also be only data) but also your prior knowledge about it. You can incorporate that into a prior^[Prior probability distribution, often simply called the prior.]. But beware, this should be done before peeking into data. 

If you don't know anything about proportion of sea on earth you can assign the same probability to all values of `p`. That's called a flat prior. You usually want to avoid it. It means you haven't "done your homework" and have no idea what about the process you're modeling. 

For example, if you know that there's more than 50% of water on sea surface, you can assign 0 probability when `p` is less than 0.5.^[Beware, this means that `p` won't be lower than 0.5 no matter the data.] Or if you know the probability should be around 0.5, you can use normal (or [beta](https://en.wikipedia.org/wiki/Beta_distribution) distribution) with the mean of 0.5.

![Examples of different priors. Note that priors' probability densities have to sum to one. ](../../images/bayesian-updating/prior.png)


## Likelihood
Likelihood tells you how likely is that "data generator", in our case flipping machine with `p` probability of success, would produce such outcome (data). In our example, there are only two outcomes for which we need to figure out the likelihoods. What's the probability, for example, if `p = 0.9` the outcome equals 1? it's 0.9, you're right. And that holds for all `p` values between 0 and 1. We only need to standardize it to get the likelihood so all the probabilities for different `p` sum up to 1. And for 0 outcome, the probability is `1-p`, so 0.1 for `p = 0.9`. And then we have to normalize it (dividing each value by their sum). 

Why normalize? All possibilities have to sum to 1. Because if `p = 1` then the probability it will produce 1 is `1`. This doesn't mean there's 100% chance that outcome 1 was generated by `p = 1`. Also other `p` can generate 1. 

![Likelihood for earth tossing outcomes. Each has to sum up to 1.](../../images/bayesian-updating/likelihood.png)

## Posterior
Posterior is what we are interested in. It tells the plausability of each `p` given it's prior probability and data. It's proportional to a product of likelihood and prior for each value of `p`. To get a posterior value of some `p`, let's say `p = 0.9`, you just multiply prior probability that `p = 0.9` and likelihood probability that `p = 0.9` generated observed data. Then you need to normalize it, how big this product is compared to other `p` values. This means summing (or integrating) such products over all `p` values. And this values can be either discrete or continuous. 

### Bayesian updating
But the fun doesn't end there. Let's say you observed multiple tosses and got outcomes `010`. To get the posterior you need to calculate likelihood for such outcome, or - wait for it - you could do it iteratively. After each toss, each posterior can be used as a prior for the next toss. This means you can just calculate posterior as a normalized product of a prior and likelihood for each outcome. Like this:

![Bayesian magic. For each `p` you just multiply prior  and likelihood densities to get a posterior one (NOT REALLY). This can be done interactively (point by point) - so for example, prior densitity and likelihood of the first oucome can be used as a prior for the next outcome.](../../images/bayesian-updating/posterior.png)

Simple multiplication means that posterior after `011` is the same as after `110` or `101`. It also takes care that `01` is not the same as `0011`. The posterior is narrower in the latter case. 

### App

I also created a shiny reactive app where you can observe Bayesian updating and get intuition about it. It enables to play around with different priors, trial (toss) outcomes, and observe changes in posterior. 

<iframe width='1000px' height='600px' src='https://mihagazvoda.shinyapps.io/bayesian-updating/' >
  <p>Bayesian updating for dummies</p>
</iframe>

## How to do it in R
Maybe move it to the next post?

```{r echo = TRUE}
# define number of equidistant points between 0 and 1
n <- 11
p_grid <- seq(from = 0, to = 1, length.out = n)

# define prior
prior <- rep(1, n)

# compute likelihood at each value in grid
likelihood <- dbinom(1, size = 3, prob = p_grid)

# compute product of likelihood and prior
unstandardized_posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstandardized_posterior / sum(unstandardized_posterior)
```

```{r}
library(ggplot2)

ggplot(tibble::tibble(p_grid, posterior), aes(p_grid, posterior)) +
  geom_line() +
  geom_point() + 
  theme_classic()
```



then you can just multiply columns to get posteriors!

> When we don't know what caused the data, potential causes that may produce the data in more ways are more plausible. - Statistical Rethinking

also add link to dashboard and R code

also add example what happens if you have 01 vs 0011 (it shrinks)

From Statistical Rethinking:

* The relative number of ways that a value p can produce the data is usually called a **likelihood**. It is derived by enumerating all the possible data sequences that could have happened and then eliminating those sequences inconsistent with the data.

* The **prior** plausibility of any specific p is usually called the prior probability.

* The new, updated plausibility of any specific p is usually called the **posterior** probability.
