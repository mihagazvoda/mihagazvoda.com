---
title: "Intuitive Bayesian updating for binomial data"
description: |
  With interactive app and examples in R.
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 11-24-2020
output:
  distill::distill_article:
    self_contained: false
---

I've struggled many time to dive into Bayesian statistics especially inference. I attended probably 10+ hour course (and passed it) without properly understanding what I'm doing. Then I, while watching [the talk about linear models and using common sense](https://www.youtube.com/watch?v=68ABAU_V8qI), came across Statistical Rethinking [book](https://xcelab.net/rm/statistical-rethinking/) and [video course](https://www.youtube.com/watch?v=4WVelCswXo4). [^1]

[^1]: I think they supplement each other well. If you need to pick one, go with the book. 

While the first chapter can be a bit boring I cannot recommend it enough. The author focuses that you grasp the topic without (almost any) equations but with common sense. And I started to understand what's going on. And even more importantly - I figured out that I learn by doing - not by listening. That's how this article (and a dashboard, but more on this later) was born.[^2]

[^2]: I'm at chapter 4 so don't expect too much.

## Tossing, again

The author introduces earth tossing example for approximating proportion of sea on the earth. You throw globe in the air, catch it, check your index finger, write down if it's sea (1 = success) or land (0 = failure). By throwing and catching it a lot of times you could estimate proportion of sea on the earth. But how sure can you be about the estimation?

TODO paste possible outcomes

Let's say `p` is probability of success, i.e. probability that we will catch the earth pointing on sea which translates into proportion of earth's surface covered by the sea. Based on tossing outcomes we will estimate how likely is that each of that `p` could generate such data. By each `p` I mean all probabilities of success, from 0 to 1. (To keep things shorter (not even simpler) let's focus on each tenth percent. Maybe mention outcomes that you plan to use?)

## Priors

In Bayesian world, there's no only data (it could also be only data) but also your prior knowledge about it. You can incorporate that into a prior^[Prior probability distribution, often simply called the prior.]. But beware, this should be done before peeking into data. 

If you don't know anything about proportion of sea on earth you can assign the same probability to all values of `p`. That's called a flat prior. You usually want to avoid it. It means you haven't done your homework and have no idea what about the process you're modeling. 

For example, if you (100%) know that there's more than 50% of water on sea surface, you can assign 0 probability to when `p` is less than 0.^[Beware, this means that `p` won't be lower than 0.5 no matter the data.] Or if you know the probability should be around 0.5, you can using Gaussian with mean of 0.



TODO add drawing of different priors


## Likelihood
Likelihood tells you how likely is that model, in our case `p`, would produce such outcome (data). In our example, there are only two outcomes for which we need to figure out the likelihoods. What's the probability, for example, if `p = 0.9` the outcome equals 1? it's 0.9, you're right. And that holds for all `p` values between 0 and 1. We only need to standardize it to get the likelihood so all the probabilities for different `p` sum up to 1. And for 0 outcome, the probability is `1-p`, so 0.1 for `p = 0.9`. And again summing all and dividing. 

Why standardizing? All possibilities have to sum to 1. Because if `p = 1` then the probability it will produce 1 is `1`. This doesn't mean there's 100% chance that outcome 1 was generated by `p = 1`. Also other `p` can generate 1. 

TODO drawing

## Posterior
Posterior is what we are interested in. It tells you the plausability of each `p` given it's prior probability and data. It's proportional to a product of likelihood and prior for each value of `p`. So for some value of `p`, let's say `p = 0.9` you just multiply prior probability that `p = 0.9` and likelihood probability that `p = 0.9` generated observed data. Then you need to normalize it, how big this product is compared to other `p` values. This means summing (or integrating) such products over all `p` values. And this values can be either discrete or continuous. 

## Bayesian updating
But the fun doesn't end there. Let's say you observed multiple tosses and got outcomes `010`. To get the posterior:You need to calculate likelihood for such outcome, or - wait for it - you could do it iteratively. After each toss, each posterior can be used as a prior for the next toss. This means you can just calculate posterior as a normalized product of a prior and likelihood for each outcome. Like this:

TODO posterior image

Simple multiplication means that posterior after `011` is the same as after `110`. It also takes care that `01` is not the same as `0011`. The posterior is narrower in the latter case. You can observe this and get intuition with the reactive app I created. It enables to play around with different priors, trial (toss) outcomes, and observe changes in posterior. 

<iframe width='1000px' height='600px' src='https://mihagazvoda.shinyapps.io/bayesian-updating/' >
  <p>Byesian updating for dummies</p>
</iframe>



TODO add maths session in html detail?



## How to do it in R


then you can just multiply columns to get posteriors!

> When we don't know what caused the data, potential causes that may produce the data in more ways are more plausible. - Statistical Rethinking

also add link to dashboard and R code

also add example what happens if you have 01 vs 0011 (it shrinks)

From Statistical Rethinking:

* The relative number of ways that a value p can produce the data is usually called a **likelihood**. It is derived by enumerating all the possible data sequences that could have happened and then eliminating those sequences inconsistent with the data.

* The **prior** plausibility of any specific p is usually called the prior probability.

* The new, updated plausibility of any specific p is usually called the **posterior** probability.
