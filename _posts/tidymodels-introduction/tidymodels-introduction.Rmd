---
title: "Tidymodels introduction"
description: |
  A short description of the post.
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 02-13-2021
output:
  distill::distill_article:
    self_contained: false
---

Do you like [`tidyverse`](https://www.tidyverse.org/) and machine learning? Then you'll love [`tidymodels`](https://www.tidymodels.org/): 

> The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.

If you would like to start, their [Get started](https://www.tidymodels.org/start/) page is great. There's even an upcoming `tidymodels` [book](https://www.tmwr.org/). The goal of this post is to show how I use them and create a boiler plate for my future use.

# tidymodels' packages


  * [usemodels](https://usemodels.tidymodels.org/) boilerplate
  * [workflows](https://workflows.tidymodels.org/)
  * [rsample]()
  * [recipes]()
  * [parsnip]()
  * [tune](https://tune.tidymodels.org/)

```{r include=TRUE, echo=TRUE}
prepare_recipe <- function(train_data_raw) { # TODO add missing argument for y instead of mpg
  recipe(mpg ~ ., data = train_data_raw) %>% 
    step_normalize(all_numeric(), id = "you_can_use_id") %>% 
    prep()
}

fit_model <- function(train_data) {
  linear_reg() %>% 
    set_engine("lm") %>% 
    fit(mpg ~ ., data = train_data)
}

create_predictions <- function(model, data) {
  select(data, actual = mpg) %>% 
    bind_cols(predict(model, new_data = data)) %>% 
    bind_cols(predict(model, new_data = data, type = "pred_int", level = 0.95))
}
```


```{r include=TRUE, echo=TRUE}
library(dplyr)
library(purrr)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)

data <- tibble(mtcars)

# decide how big should be assessment size
df <- vfold_cv(data, v = 10, prop = 0.5)

# this doesn't make sense since it's the same recipe for all data, does it?
df$recipe <- map(df$splits, ~prepare_recipe(analysis(.)))

df$train_data <- map2(df$splits, df$recipe, ~bake(.y, analysis(.x)))
df$test_data <- map2(df$splits, df$recipe, ~bake(.y, assessment(.x)))

df$model <- map(df$train_data, fit_model)

df$predictions <- map2(df$model, df$test_data, create_predictions)

df$evaluation <- map(df$predictions, metrics, truth = actual, estimate = .pred)
```

# Tune metaparameters


```{r include=TRUE, echo=TRUE}
tune_spec <- rand_forest(
  mtry = tune(),
  trees = 20,
  min_n = tune()
) %>%
  set_mode("regression") %>%
  set_engine("ranger")
```


```{r include=TRUE, echo=TRUE}
tune_wf <- workflows::workflow() %>% 
  workflows::add_recipe(df$recipe[[1]]) %>% 
  workflows::add_model(tune_spec)
```




```{r include=TRUE, echo=TRUE}
# doParallel::registerDoParallel()
# trees_folds <- vfold_cv(data)
# 
# tune_res <- tune::tune_grid(
#   tune_wf,
#   resamples = trees_folds,
#   grid = 10
# )
# 
# tune_res$.metrics[[1]]
```








