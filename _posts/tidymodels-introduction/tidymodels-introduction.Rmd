---
title: "Tidymodels introduction"
description: |
  A short description of the post.
author:
  - name: Miha Gazvoda
    url: https://mihagazvoda.com
date: 02-13-2021
output:
  distill::distill_article:
    self_contained: false
---

Do you like [`tidyverse`](https://www.tidyverse.org/) and machine learning? Then you'll love [`tidymodels`](https://www.tidymodels.org/). As their website says: 

> The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.

If you would like to start with them, [Get started](https://www.tidymodels.org/start/) page is great. There's even an upcoming [book](https://www.tmwr.org/) about them. The goal of this post is to show how I use them and create a boiler plate for my future use. So my bet is that the most frequent visitor of this website will be me. 

# Tidymodels' packages
  * [usemodels](https://usemodels.tidymodels.org/) boilerplate
  * [workflows](https://workflows.tidymodels.org/)
  * [rsample]()
  * [recipes]()
  * [parsnip]()
  * [tune](https://tune.tidymodels.org/)

<!-- TODO check parameter tuning in device quality model -->

```{r include=TRUE, echo=TRUE}
prepare_recipe <- function(train_data_raw) { # TODO add missing argument for y instead of mpg
  recipe(mpg ~ ., data = train_data_raw) %>% 
    step_normalize(all_numeric(), id = "you_can_use_id") %>% 
    prep()
}

fit_model <- function(train_data) {
  linear_reg() %>% 
    set_engine("lm") %>% 
    fit(mpg ~ ., data = train_data)
}

create_predictions <- function(model, data) {
  select(data, actual = mpg) %>% 
    bind_cols(predict(model, new_data = data)) %>% 
    bind_cols(predict(model, new_data = data, type = "pred_int", level = 0.95))
}
```


```{r include=TRUE, echo=TRUE}
library(dplyr)
library(purrr)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)

data <- tibble(mtcars)

# decide how big should be assessment size
df <- vfold_cv(data, v = 10, prop = 0.5)

df$recipe <- map(df$splits, ~prepare_recipe(analysis(.)))

df$train_data <- map2(df$splits, df$recipe, ~bake(.y, analysis(.x)))
df$test_data <- map2(df$splits, df$recipe, ~bake(.y, assessment(.x)))

df$model <- map(df$train_data, fit_model)

df$predictions <- map2(df$model, df$test_data, create_predictions)

df$evaluation <- map(df$predictions, metrics, truth = actual, estimate = .pred)
```

# Tune metaparameters











```{r}
library(workflows)

wf <- workflow() %>% 
  add_recipe(df$recipe[[1]]) %>% 
  add_model(set_engine(linear_reg(), "lm"))

wf_fit <- fit(wf, mtcars)
```







