[
  {
    "path": "posts/wall-riddle/",
    "title": "The wall riddle",
    "description": "Bayesian approach for dealing with biased data.",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2021-02-07",
    "categories": [
      "R",
      "Bayesian",
      "data science"
    ],
    "contents": "\nI received the following riddle when asking for Bayesian resources on Twitter:\n\nSolve this riddle.\nThere is a wall that’s kind of tall but not too tall, say 1.8m. You can only see the people who are taller than the wall.\nSuppose you saw 1m88, 1m90 and 1m81.\nWhat can you say about everyone who walked past the wall?\n\n— Vincent D. Warmerdam\n\nChallenge accepted.\nLet’s pretend there’s a group of people standing instead of walking behind a wall. This way it’s easier to sketch the situation. That’s what we see:\n\nThis is the view from ahead:\n\nBayes to the rescue!\nLet’s assume people’s heights are normally distributed with some mean \\(\\mu\\) and standard deviation \\(\\sigma\\). A part of this distribution can’t be observed since it’s behind a wall.\nGaussian distribution with parameters \\(\\mu\\) and \\(\\sigma\\) describing heights of all people. Only the part of distribution above the wall \\(h_w\\) is observed.We will start with Bayes’ theorem. We are interested in posterior distribution \\(p(\\mu, \\sigma | D_{bias})\\) of parameters \\(\\mu\\) and \\(\\sigma\\) that describe the height of people behind a wall given the observed heights \\(D_{bias}\\). Since \\(p(D_{bias})\\) serves as a normalizing constant that makes the posterior density integrate to one, we can throw it away.1 Prior \\(p(\\mu,\\sigma)\\) can be rewritten as the product of priors for each parameter. The likelihood is a product of the likelihoods of all observed heights.\n\\[\np(\\mu, \\sigma | D_{bias}) = \\frac{p(D_{bias} | \\mu, \\sigma) p(\\mu, \\sigma)}{p(D_{bias})} \\propto p(D_{bias} | \\mu, \\sigma) p(\\mu, \\sigma) = p(\\mu)p(\\sigma) \\prod_{i} p(h_i | \\mu, \\sigma)\n\\]\nThe tricky part is to calculate \\(p(h_i | \\mu, \\sigma)\\). We can help ourselves with the sketch above. Our observations come only from the part of the distribution that is above the wall. So likelihoods are basically the same as from Gaussian but normalized by the density portion that is above the wall. Without getting too much into maths2, this can be easily calculated in R with functions dnorm(), to get values for probability density, and pnorm() to get the probability that the observation is taller than the wall:\n\\[\np(h_i | \\mu, \\sigma) = \\frac{dnorm(h_i, \\mu, \\sigma)}{pnorm(h_w, \\mu, \\sigma)}\n\\]\nBoth functions can take vectors for argument values. Then you multiply likelihoods for all the points. Here’s an R function that does that: \n\n\ncalc_likelihood <- function(mu, sigma, observations, wall) {\n  prod(\n    dnorm(observations, mu, sigma) /\n      pnorm(wall, mu, sigma, lower.tail = FALSE)\n  )\n}\n\n\n\nMultiplication is all you need.\nOnce we know how to calculate the likelihood, the simplest way to calculate the posterior (plausibility of the parameters of Gaussian describing all people standing behind a wall) is a grid approximation. I find it the clearest but it uses brute-force that is suitable only for the low number of parameters. It goes like this:\nDecide on appropriate sequences of parameters values \\(\\mu\\) and \\(\\sigma\\) and their priors.3 This is done in df_mu and df_sigma. Note that you can easily create Gaussian priors using dnorm() function with parameter values set as the first argument. I decided to use flat priors instead so one can’t argue that the shift in posterior mu values happened due to priors, not the wall. Flat priors also mean the posterior will be proportional to the likelihood.\nCreate a grid of parameter combinations. Function crossing() does that.\nCalculate likelihood for each combination of parameters and observed heights by calling function calc_likelihood() on each row.\nCalculate posterior as a product of likelihood and parameters’ posteriors. Normalize the posterior to see what’s the posterior probability of some parameter combination among all defined parameter combinations.\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\nwall <- 180\nobservations <- c(181, 188, 190)\n\ndf_mu <- tibble(\n  mu = seq(170, 190, by = 0.1),\n  prior_mu = 1 # dnorm(mu, 178, 10)\n)\n\ndf_sigma <- tibble(\n  sigma = seq(1, 20, by = 0.1),\n  prior_sigma = 1 # dnorm(sigma, 10, 5)\n)\n\ndf <- crossing(df_mu, df_sigma) %>%\n  rowwise() %>%\n  mutate(likelihood = calc_likelihood(mu, sigma, observations, wall)) %>% \n  ungroup() %>% \n  mutate(\n    posterior_unstd = likelihood * prior_mu * prior_sigma,\n    posterior = posterior_unstd / sum(posterior_unstd)\n  )\n\n\n\nPosterior looks beautiful but does it make sense?\nLet’s see the results in df sorted by descending posterior:\n\nmu\nprior_mu\nsigma\nprior_sigma\nlikelihood\nposterior_unstd\nposterior\n185.0\n1\n4.8\n1\n3.1452e-04\n3.1452e-04\n6.7623e-05\n185.1\n1\n4.8\n1\n3.1449e-04\n3.1449e-04\n6.7617e-05\n184.9\n1\n4.9\n1\n3.1442e-04\n3.1442e-04\n6.7602e-05\n185.0\n1\n4.9\n1\n3.1439e-04\n3.1439e-04\n6.7596e-05\n185.1\n1\n4.7\n1\n3.1434e-04\n3.1434e-04\n6.7584e-05\n185.2\n1\n4.7\n1\n3.1430e-04\n3.1430e-04\n6.7576e-05\n\nThe most likely parameters for Gaussian distribution describing people height standing behind a wall are \\(\\mu \\approx 185cm\\) and \\(\\sigma \\approx 4.8cm\\). Note that \\(\\mu\\) is smaller compared to the average of observations \\(\\bar{h} = 186.3cm\\).\n\n\n\n\nAdditional plot to better understand the posterior.\nThe plot below displays normalized probability densities for heights between 180 and 190cm. The normalized probability density is calculated the same as in \\(p(h_i|\\mu, \\sigma)\\) above; that is divided by the portion of the Gaussian above the wall height.\n\n\n\nTo get the posterior value for some \\(\\mu\\) and \\(\\sigma\\) you just have to multiply densities (y values on the plot). We can see that \\(\\sigma\\) between 10 and 15 make the more sense because higher \\(\\sigma\\) values are lower for all heights and small \\(\\sigma\\) density for height 181cm is bigger but gets compensated because when multiplying with densities for 188 and 190 which are way smaller.\nDon’t give up when your data is biased.\nAbout another such example, getting customer complaints about their waiting time only when they’ve been waiting for longer than usual, talked Vincent on PyData. He also explains the riddle I’ve solved without giving the the solution.\nA lot of data we collect is biased and sometimes we know how it is biased. Luckily - and skillfully - we can make up for that.\n\nMore about that on Cross Validated.↩︎\nOk, if you really want it: \\[\np(h_i | \\mu, \\sigma) = \\frac{exp(\\frac{-(h_i-\\mu)^2}{2\\sigma^2})/(\\sigma \\sqrt{2\\pi})}{\\int_{x=h_w}^{\\infty}(exp(\\frac{-(x-\\mu)^2}{2\\sigma^2}) / (\\sigma \\sqrt{2\\pi}))}\n\\] It’s way simpler than it looks.↩︎\nUsually, priors should be probability densities (so they integrate to 1) but in our case this is not a problem since we will normalize posterior at the end.↩︎\n",
    "preview": "posts/wall-riddle/../../images/wall-puzzle/behind.png",
    "last_modified": "2021-02-07T17:39:11+01:00",
    "input_file": {},
    "preview_width": 1200,
    "preview_height": 900
  },
  {
    "path": "posts/2020-11-24-bayesian-updating/",
    "title": "Intuitive Bayesian inference",
    "description": "Binomial data example",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2021-01-02",
    "categories": [
      "data science",
      "Bayesian",
      "Shiny"
    ],
    "contents": "\nI’ve struggled many times to dive into Bayesian inference. I attended a 10+ hour course (and passed it) without properly understanding what’s going on. Then, while watching the talk about linear models and using common sense1, I came across Statistical Rethinking book and video course. 2\nIn the early chapters, the author focuses on presenting the topic with simple examples that can be solved without equations. And I started to understand what’s going on. Besides that, I figured out that I learn by doing - not by listening. That’s how this article (and a dashboard) was born.\nTossing\nThe author introduces an earth tossing example for approximating the proportion of water on the earth’s surface. You throw a globe in the air, catch it, check your index finger, write down if it’s water (1 = success) or land (0 = failure). By throwing it a lot of times you could estimate the proportion of water on earth. But how sure can you be about the estimation?\nLet’s say p is a parameter of our model and presents a probability of success, i.e. probability that we will catch the earth pointing on the water which translates into the proportion of earth’s surface covered by water. Based on tossing outcomes we will estimate how likely is that each of that p could generate such data. By each p I mean all probabilities of success, from 0 to 1. They can be continuous or discrete. For example, you can focus only on each tenth quantile.\n\nPrior\nIn the Bayesian world, your prior knowledge counts. If you don’t have it, also fine, but your inference won’t be as precise as it could be. In this example, prior knowledge about the parameter p is incorporated into the prior. Generally, this should be done before peeking into data.\nIf you don’t know anything about the proportion of water on earth you can assign the same probability to all values of parameter p. That’s called a flat prior. You usually want to avoid it.\nIf you know that there’s more than 50% of water on the earth’s surface, you can assign 0 prior probability to p less than 0.5.3 Or if you suspect the probability should be around 0.5, you can use normal (or beta distribution) with the mean of 0.5. It also doesn’t make sense to use too big standard deviations and cut off values below 0 and above 1.\n\n\nLikelihood\nLikelihood tells you how likely a model with parameter value p probability of success would produce such outcome(s). In our example, there are only two possible outcomes, 0 and 1, for which we need to figure out the likelihoods.\nWhat’s the probability, for example, that the model with p = 0.9 produces the outcome 1? It’s 0.9, you’re right. For 0.8, it’s 0.8, and so on. That holds for all parameter values between 0 and 1. It’s a linear relationship where higher p values have higher probability density (when outcome equals 1). You can see it on the sketch below. We only need to normalize it to get the likelihood so all the probabilities for different p sum up to 1. And for outcome 0, the probability is 1-p. So 0.1 for p = 0.9, for example.\nWhy normalization? All possibilities have to sum to 1. Because if p = 1 then the probability it will produce 1 is 1. This doesn’t mean there’s a 100% chance that outcome 1 was generated by p = 1. Other p can also generate outcome 1.\n\nThe likelihood for earth tossing outcomes. Each has to sum up to 1.\nPosterior\nPosterior is what we are interested in. It tells the plausibility of each parameter p given its prior probability and data. It’s proportional to a product of likelihood and prior for each value of p. To get a posterior value for p = 0.9, you just multiply the prior probability that p = 0.9 and the likelihood probability that such p generated observed data. Then you need to normalize it by dividing the posterior value by the sum of posteriors for all p.\nBayesian updating\nBut the fun doesn’t end there. Let’s say you observed multiple tosses and got outcomes 010. To get the posterior you need to calculate the likelihood for such an outcome, or - wait for it - you can do it iteratively. After each toss, each posterior can be used as a prior for the next toss. This means you can just calculate posterior as a normalized product of a prior and likelihood for each outcome. Like this:\n\nBayesian magic. For each p you multiply prior and likelihood densities to get a proportional posterior. This can be done iteratively - for example, prior density and likelihood of the first outcome can be used as a prior for the next outcome. Note that the axes are flipped.\nSimple multiplication means that posterior after 011 is the same as after 110 or 101. It also takes care that 01 is not the same as 0011. The posterior is narrower in the latter case.\nPlayground\nI created a Shiny reactive app (see code) where you can observe Bayesian updating and get an intuition about it. It enables to play around with different priors, trial (toss) outcomes, and observe changes in posterior.\n\n\nBayesian updating for dummies\n\n\nIt’s (like) magic, isn’t it?\n\nSee the above example in R.\nThis method is called grid approximation. It means considering only a finite grid of parameter values (although the parameter is continuous).\n\n\n# define number of equidistant points between 0 and 1\n  n <- 11\n  p_grid <- seq(from = 0, to = 1, length.out = n)\n  \n  # define flat prior (unstandardized)\n  prior <- rep(1, n)\n  \n  # compute likelihood at each value in grid for 1 success in 3 trials\n  likelihood <- dbinom(1, size = 3, prob = p_grid)\n  \n  # compute product of likelihood and prior\n  unstandardized_posterior <- likelihood * prior\n  \n  # standardize the posterior, so it sums to 1\n  posterior <- unstandardized_posterior / sum(unstandardized_posterior)\n  \n\n\n\n\n\n\nVincent gave a couple of amazing talks on solving problems using Bayesian inference. Take a look.↩︎\nI think they supplement each other well. If you need to pick one, go with the book. The first two chapters are available for free.↩︎\nThis means that p won’t be lower than 0.5 no matter the data.↩︎\n",
    "preview": "posts/2020-11-24-bayesian-updating/../../images/bayesian-updating/globe.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 600,
    "preview_height": 450
  },
  {
    "path": "posts/2020-04-21-drake-tutorial/",
    "title": "Improve your data analysis workflow with the drake R package",
    "description": "A quick guide.",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2020-10-30",
    "categories": [
      "data science",
      "R"
    ],
    "contents": "\ndrake is an R package by Will Landau that analyzes your workflow. It\nenables to skip steps of the analysis with up-to-date results;\nprovides evidence that results match the underlying code and data;\nencourages good programming practices by modularizing your code into functions1;\ninteractively visualizes network representation of your workflow.\nPerks of using drake.Setup\nInstall drake. You can also load an example written by Kirill Müller. It will appear in a new main folder. I will use it as a showcase for some file examples.\n\n\n# Install and load drake\ninstall.packages(\"drake\")\n\n# Get an example in a new `main` folder\ndrake::drake_example(\"main\")\n\n# You can use drake::examples() to see all examples\n\n\n\nProject structure\nIt’s suggested that you start your project using this structure2:\nmake.R\nR/\n├── packages.R\n├── functions.R\n└── plan.R\ndata/\nYou can also use dflow::use_dflow() to create almost similar structure.\nMake\nmake.R is a master script that\nloads your packages and functions3;\ncreates a drake plan;\ncalls make().\n\n\n# make.R\nsource(\"R/packages.R\")  # loads packages\nsource(\"R/functions.R\") # loads user-defined functions\nsource(\"R/plan.R\")      # creates drake plan\n\nmake(plan)              # defined in R/plan.R\n\n\n\nPlan\ndrake plan is the high-level catalog of data analysis steps (such as data cleaning, model fitting, visualization, and reporting) in a workflow.\nPlan is presented as a data frame with columns named target and command.\n\n\n# plan.R\n# The workflow `plan` data frame outlines what you are going to do.\nplan <- drake::drake_plan(\n  # target, command\n  raw_data = readxl::read_excel(file_in(\"raw_data.xlsx\")),\n  data = raw_data %>%\n    mutate(Species = forcats::fct_inorder(Species)),\n  hist = create_plot(data),\n  fit = lm(Sepal.Width ~ Petal.Width + Species, data),\n  report = rmarkdown::render(\n    knitr_in(\"report.Rmd\"),\n    output_file = file_out(\"report.html\"),\n    quiet = TRUE\n  )\n)\n\n\n\nDrake plan is presented as a data frame with columns named target and command. Each row represents a step in the workflow. Each command is a concise expression that makes use of our functions, and each target is the return value of the command.\nSee plan object.\n\ntarget\ncommand\nraw_data\nreadxl::read_excel(file_in(“raw_data.xlsx”))\ndata\nraw_data %>% mutate(Species = forcats::fct_inorder(Species))\nhist\ncreate_plot(data)\nfit\nlm(Sepal.Width ~ Petal.Width + Species, data)\nreport\nrmarkdown::render(knitr_in(“report.Rmd”), output_file = file_out(“report.html”), , quiet = TRUE)\n\nSee dependency graph.\n\n\n{\"x\":{\"nodes\":{\"id\":[\"n-OJSWCZDYNQ5DU4TFMFSF6ZLYMNSWY\",\"p-OJQXOX3EMF2GCLTYNRZXQ\",\"n-OJWWC4TLMRXXO3R2HJZGK3TEMVZA\",\"p-OJSXA33SOQXFE3LE\",\"n-MZXXEY3BORZTUOTGMN2F62LON5ZGIZLS\",\"raw_data\",\"report\",\"data\",\"p-OJSXA33SOQXGQ5DNNQ\",\"fit\",\"hist\"],\"imported\":[true,true,true,true,true,false,false,false,false,false,false],\"label\":[\"readxl::read_excel\",\"file raw_data.xlsx\",\"rmarkdown::render\",\"file report.Rmd\",\"forcats::fct_inorder\",\"raw_data\",\"report\",\"data\",\"file report.html\",\"fit\",\"hist\"],\"status\":[\"imported\",\"missing\",\"imported\",\"missing\",\"imported\",\"outdated\",\"outdated\",\"outdated\",\"outdated\",\"outdated\",\"outdated\"],\"type\":[\"function\",\"file\",\"function\",\"file\",\"function\",\"object\",\"object\",\"object\",\"file\",\"object\",\"object\"],\"font.size\":[20,20,20,20,20,20,20,20,20,20,20],\"color\":[\"#1874CD\",\"#9A32CD\",\"#1874CD\",\"#9A32CD\",\"#1874CD\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\"],\"shape\":[\"triangle\",\"square\",\"triangle\",\"square\",\"triangle\",\"dot\",\"dot\",\"dot\",\"square\",\"dot\",\"dot\"],\"level\":[1,1,1,1,1,2,2,3,3,4,4],\"x\":[-1,-1,-1,-1,-1,-0.333333333333333,-0.333333333333333,0.333333333333333,0.333333333333333,1,1],\"y\":[-1,-0.5,2.22044604925031e-16,0.5,1,-0.5,0.5,-0.5,0.5,-0.5,0.5]},\"edges\":{\"from\":[\"n-OJSWCZDYNQ5DU4TFMFSF6ZLYMNSWY\",\"p-OJQXOX3EMF2GCLTYNRZXQ\",\"n-OJWWC4TLMRXXO3R2HJZGK3TEMVZA\",\"p-OJSXA33SOQXFE3LE\",\"report\",\"data\",\"data\",\"raw_data\",\"n-MZXXEY3BORZTUOTGMN2F62LON5ZGIZLS\"],\"to\":[\"raw_data\",\"raw_data\",\"report\",\"report\",\"p-OJSXA33SOQXGQ5DNNQ\",\"fit\",\"hist\",\"data\",\"data\"],\"arrows\":[\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\"]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\",\"physics\":false},\"manipulation\":{\"enabled\":false},\"edges\":{\"smooth\":{\"type\":\"cubicBezier\",\"forceDirection\":\"horizontal\"}},\"interaction\":{\"navigationButtons\":true},\"layout\":{\"hierarchical\":{\"enabled\":true,\"direction\":\"LR\"}}},\"groups\":null,\"width\":null,\"height\":null,\"idselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"useLabels\":true,\"main\":\"Select by id\"},\"byselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"multiple\":false,\"hideColor\":\"rgba(200,200,200,0.5)\",\"highlight\":false},\"main\":{\"text\":\"Dependency graph\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-weight:bold;font-size:20px;text-align:center;\"},\"submain\":null,\"footer\":null,\"background\":\"rgba(0, 0, 0, 0)\",\"highlight\":{\"enabled\":false,\"hoverNearest\":false,\"degree\":1,\"algorithm\":\"all\",\"hideColor\":\"rgba(200,200,200,0.5)\",\"labelOnly\":true},\"collapse\":{\"enabled\":true,\"fit\":false,\"resetHighlight\":true,\"clusterOptions\":null,\"keepCoord\":true,\"labelSuffix\":\"(cluster)\"},\"legend\":{\"width\":0.2,\"useGroups\":false,\"position\":\"left\",\"ncol\":1,\"stepX\":100,\"stepY\":100,\"zoom\":true,\"nodes\":{\"label\":[\"Outdated\",\"Imported\",\"Missing\",\"Object\",\"Function\",\"File\"],\"color\":[\"#000000\",\"#1874CD\",\"#9A32CD\",\"#888888\",\"#888888\",\"#888888\"],\"shape\":[\"dot\",\"dot\",\"dot\",\"dot\",\"triangle\",\"square\"],\"font.color\":[\"black\",\"black\",\"black\",\"black\",\"black\",\"black\"],\"font.size\":[20,20,20,20,20,20],\"id\":[2,6,7,8,10,11]},\"nodesToDataframe\":true},\"tooltipStay\":300,\"tooltipStyle\":\"position: fixed;visibility:hidden;padding: 5px;white-space: nowrap;font-family: verdana;font-size:14px;font-color:#000000;background-color: #f5f4ed;-moz-border-radius: 3px;-webkit-border-radius: 3px;border-radius: 3px;border: 1px solid #808074;box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);\"},\"evals\":[],\"jsHooks\":[]}\nChoose good targets\nAs Will Landau proposed, a good target is\nlong enough to eat up a decent chunk of runtime;\nsmall enough that make() frequently skips it;\nmeaningful to your project;\nan R object compatible with saveRDS().\nWorkflow\nEven if you use drake, it makes sense to develop interactively. With r_make(\"make.R\")4 you build your project. With loadd and readd you return targets to your session and interactively use them to develop things further.\nBasic commands\nHere are the most useful commands.\n\nfunction\ndescription\nr_make()\nBuild your project.\nclean()\nForce targets to be out of date and remove target names from the data in the cache.\nvis_drake_graph()\nShow an interactive visual network representation of your workflow.\ncode_to_function()\nCreate functions from scripts so you can pass them as commands in drake plan.\nloadd()\nLoads built target(s) into your R session.\nreadd()\nRead and return a built target.\n\nYou can find more functions in drake README.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nFor further reading I suggest you The drake R package User Manual. The book also served as a resource for this post.\n\nMore about functions in R.↩︎\nIt’s almost the same as in the example.↩︎\nIf there are many functions, split them up into multiple files.↩︎\nIf you name make file _drake.R instead, you are able to call r_make() without an argument.↩︎\n",
    "preview": "posts/2020-04-21-drake-tutorial/../../images/drake_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-26-man-plans-god-laughs-the-planning-fallacy/",
    "title": "Man Plans, God Laughs: The Planning Fallacy",
    "description": "So you’re planning to read the whole article? Let’s see…",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2018-01-01",
    "categories": [
      "decision making under uncertainty"
    ],
    "contents": "\nOnce upon a time, there were a guy and a girl. They had a date in Sydney Opera House. She was late as usual — something unexpected had happened — she couldn’t immediately find one of her 100 makeup products. (Other times she couldn’t find the other ones, so it was always different with the same result.)\nby Jovana ĐukićWhile he was waiting, he googled fun facts about the Opera to impress her. This was what he had found on Wikipedia:\n\n“Sydney Opera House was originally scheduled for four years, with a budget of AUS $7 million. It ended up taking 14 years to be completed and cost AUS $102 million.”\n\n“That’s so cool!”1 he thought. She said the same after hearing it. They have used the same phrase in the following months a lot, so they decided to get married. (She liked his fun facts and he liked her for being late — so he had enough time to find them.)\nHis stubborn mother who had divorced his father warned him that there’s a 33% to 50% chance of them getting a divorce. “Not us, mother. We love each other very much.” “Sure, because your father and I got married out of hatred.”\nThey had gotten married anyway and had done better than some marriages.\n\n“Nothing will ever separate us. We will probably be married another ten years.” — Elizabeth Taylor, five days before she and Richard Burton announced their divorce\n\nBut worse than most marriages. To be exact, worse than 67% to 50% of them.\nThe wedding present she got was a box w %>% here she could store her makeup. As a result, she stopped being late; so the guy didn’t have time to find the fun facts. And who wants to be in a marriage where the best fun fact is the prediction of your divorce?\n“Not me!” she grabbed the box and threw it on the floor. Both the box and the marriage fell apart that day.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nThe Planning Fallacy\nPeople are late, projects cost millions instead of thousands, wars take years instead of months, and why my mom always comes home with a bag full of groceries, no matter what she intended to buy? It’s the planning fallacy!\nThe concept of the planning fallacy was first introduced by Nobel Laureate Daniel Kahneman and his colleague Amos Tversky. It describes overly optimistic plans and forecasts that\nare unrealistically close to best-case scenarios\ncould be improved by consulting the statistics of similar cases.\nby Jovana ĐukićIn his book, Thinking, Fast and Slow, Kahneman describes the following forecasting story. He and his colleagues were designing a textbook to teach judgment and decision making in high school. After meeting once a week for a year, they’ve already made some progress: wrote a couple of chapters, constructed an outline of a syllabus and had run a few sample lessons.\nThey were just discussing how to estimate uncertain quantities, so Kahneman proposed that everyone wrote down their estimates of duration before finishing the textbook. The results were centered around two years.\nThen Kahneman turned to the curriculum expert (both estimated the same as others) and asked him: “How long does it usually take to construct a curriculum?”\n“Seven to ten years. Not to mention almost half of the groups gave up before,” he replied.\nKahneman dug further: “How good are we compared to other groups?”\n“Slightly below the average,” said the curriculum expert. A moment later, he raised his eyebrows, realizing the contradiction in his estimates. How can below average group outpace others by more than three years?\nIt can, but it’s foolish assuming it will.\nThe difference occurred because he used two different planning strategies. When writing down his estimate, he searched for information inside his mind, trying to envision the future. Later, with Kahneman’s help, he based the prediction on the statistics of similar situations from the outside world.\nThe Inside View\nIt’s a strategy where the group members wrote down their estimates. The strategy focuses on our specific circumstances and searches for evidence in our experiences. It’s extrapolating — assuming that existing trends will continue. There’s one problem:\n\n“The future ain’t what it used to be.“ — Yogi Berra\n\n“The reason for that [too optimistic forecasts] is that we underestimate uncertainty by compressing the range of possible uncertain states (by reducing the space of the unknown),” explains Nassim Nicholas Taleb in his bestseller The Black Swan. In other words, we underestimate what we don’t know. In Kahneman’s situation, these could be more complex chapters, illnesses, bureaucracy problems… Hundreds of things one cannot even imagine.\n\n“Unexpected always pushes in a single direction: higher costs and a longer time to completion.” — Nassim Nicholas Taleb\n\nThe longer, more complex and unique the task is, the harder the prediction. Think about the most basic one, getting up out of a chair. You can predict when you are going to stand up in case you don’t want to sit anymore — except if your friends like to play pranks with a glue.\nOn the opposite side, there are wars. Each war has its own properties: people, terrain, weather, tactics, technologies. They usually last multiple years (although predicted less). And more time means more opportunities for unexpected to struck. Would Japan attack the USA if they could predict their development of the nuclear weapons?\nEven nowadays war predictions fail miserably. The Bush administration underestimated Iraq War expenses by more than 30-fold; current expenses are around $2 trillion (initial $60 billion) and growing.\nIf there’s a lesson to be learned from the inside view, it’s Hofstadter’s Law:\n\n“It always takes longer than you expect, even if you take Hofstadter’s Law into account.“ — Douglas Hofstadter\n\nThe Outside View\nUsing statistical information from the similar projects is the cure to the planning fallacy. On average, you will face the same amount of unexpected troubles as other people.\nThe method called reference class forecasting was proposed by Flyvbjerg. It contains three steps to which I added the practical examples from Kahnemann’s story:\nIdentify an appropriate reference class: other curriculum projects.\nObtain the statistics of the reference class and generate a baseline prediction: 7 to 10 years and 40% failure rate.\nUse specific information about the case to adjust the baseline prediction: is there any evidence that our group is better/worse than others?\nKahneman’s group finished the project in eight years, close to the fastest ones. In those years, many things have changed: he wasn’t part of the group anymore and there wasn’t much interest in teaching decision making. The textbook has never made it to the schools’ benches.\nIn some cases, we already use the outside view to some extent. Think about lifespan prediction. It’s typical to use the average lifespan and add or subtract a couple of years based on the lifestyle, genetics and health situation. One doesn’t look at their own experience and declare: “I’m feeling well and I haven’t died yet, based on this evidence I’m going to live forever.”\nby Jovana ĐukićThe Optimism Bias\nThere’s one more bias responsible for the planning fallacy; the optimism bias. It’s summarized in the following quote:\n\n“Most of us view the world as more benign than it really is, our own attributes as more favorable than they truly are, and the goals we adopt as more achievable than they likely to be.” — Daniel Kahneman\n\nWe perceive events asymmetrically. We attribute successes to our skills and our failures to bad luck. But only for ourselves and people closely related to us, not the other human beings — this creates illusory superiority.\nResearchers found out that 90% of drivers think they are better than the average driver2, and most students think they are more intelligent than the average student. Following this logic, why wouldn’t we be the ones who will succeed?\nBecause everyone thinks they’re a little special but that makes no one special.\n\n“Have you ever noticed that anybody driving slower than you is an idiot, and anyone going faster than you is a maniac?” — George Carlin\n\n\n\\(\\bullet\\bullet\\bullet\\)\n\nThe newly single guy went out for a beer to cure his broken heart. He wanted to gain back his optimism (bias, but he wouldn’t admit that). When he switched to shots, he overshot. Instead of optimism about the future, he gained sorrow for the past. The phone was in his hands before friends could stop him (they were busy checking their phones).\n“i miz u;D” was the message which started to glue together the broken marriage. (She was asleep so she didn’t respond immediately — and we all know who liked to wait.)\nHowever, they didn’t need to glue together the makeup box. He bought it as a sign of their reborn love — it was the thing that made her say ‘that’s so cool’ again.\nAnd in their case, ‘oh, so cool’ wasn’t far away from saying ‘I do’.\nThey planned, God laughed.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nOriginally published in New Edge on December 29, 2017.\n\n“I believe that anyone using the phrase ‘That’s so cool’ should have to stand in the corner.” -Stephen King↩︎\nActually, more than 50% of drivers are better than the average because the distribution is skewed. There are a few drivers who are really bad (cause a lot of traffic accidents) and all the rest who have only a few traffic accidents in a lifetime. The average is somewhere in-between. Anyway, the percentage of above average drivers is not as high as 90%.↩︎\n",
    "preview": "posts/2020-03-26-man-plans-god-laughs-the-planning-fallacy/../../images/planning_fallacy_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-26-the-714-words-the-picture-cant-tell/",
    "title": "The 714 words the picture can't tell",
    "description": "I’m sorry, but the photo is private. Spoiler for friends: Instagram.",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2017-12-12",
    "categories": [
      "this happened to me"
    ],
    "contents": "\nI.\nIt started as a self-promotion: “Jova, have you seen my new shoes?”\nShe hasn’t, so she came to my and Tadej’s room to check them out. Her awkward smile told me everything and surely more than her words: “Mmm, they don’t look so bad for being completely white. Also, they seem organic.” (Seriously? They are shoes, not a vegetable. But thanks, still better than ‘they look comfortable’.) She continued, trying to change the topic: “Do you want to see my new trousers?”\n“Put them on and do not expect any mercy!” I shouted back, pretending to be hurt by her words. (That’s my defensive mechanism when I’m hurt.)\nTadej peeped over his phone (He is addicted, I sometimes call him phoney.), hoping to have a little fun: “You two should have a fashion show.”\nJana joined us; who on earth would miss that?\nII.\nI’m a yes-man when it comes to food and doing stupid things. But Jovana, she used to be a kind and good girl. Back then, I believe, she would agree only out of generosity. She would participate with her mind, not her heart. But that was before she joined us on the dark side.\n\nA few weeks ago I and Tadej were seating at our computers trading Bitcoins (reality: scrolling Facebook News Feeds). We heard someone knocking. I wanted to reach my daily step goal so I got up and crossed the room (you know, every step counts - unless you forget your phone on the table).\nAs I opened the door, the world I knew fell apart into thousand pieces. The first piece broke the bubble I’ve been living in. Second wounded the hope in humanity I had. Third, my heart. (Remaining 997 stayed in the mediocrity.)\nIt was Jovana, too lazy to take out the keys and unlock the door. The only thing I could get out of my mouth was: “Et tu, Jova?”\nCaesar used those words when he was assassinated by his son. I used them when my trust was assassinated by Jovana.\n\nBad company (I and Tadej are old hands when it comes to knocking) ruined her. She became one of us.\nIII.\nWe started searching for the appropriate clothes to match our shoes or trousers. In the meantime, another idea pooped up: “Why only the two of us? We want to laugh together, not being laughed at.”\nTadej and Jana joined us as well and things progressed to a whole new level. Clothes just weren’t enough anymore. We started adding accessories; if anyone ever dared to call that a floor cleaner or Croton Petra (for all people except Jana: the plant).\nAt the end, laughing at (sorry, with) each other, we decided the moment is too precious to keep it only in our memories.\nIV.\nOn the photo, you can find my shoes and Jovana’s trousers. Intellectual wannabe who buys The Economist but doesn’t read it (not even in the photo). The person wearing the most beautiful shoes is faced with the existential crisis of his chest hair: to shave (and do it forever) or not to shave (and be hairy forever)? Jana would rather listen to her plant growing than her flatmates. Jovana is the only one holding cleaning and mechanical products. Is she trying to send the message about the work ethics? Is she the only one who has to work ? Is that the reason she needs the same model of trousers as Mojster Miha (Bob the Builder)?\nI don’t know, she doesn’t speak to me anymore.\nV.\nOne day, when my shoes will finally be organic and Tadej will finish (or at least start) reading The Economist, I will find this story in a drawer. “Who are those adolescents showing off like baboons?” I will frown while searching for my glasses. Then I will recognize us. And no, I won’t be sentimental. I will grab my phone, call these baboons, and organize a dinner.\nWhile eating Jovana’s chili con carne, Jana’s vegetarian specialties, Tadej’s curry, and drinking my water, we will be laughing again. One of us will stand up and make a toast: “To the first flatmate’s dinner we’ve been able to organize.” And then we will laugh even harder.\n\n\n\n",
    "preview": "posts/2020-03-26-the-714-words-the-picture-cant-tell/../../images/words_714_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-26-how-i-built-my-first-memory-palace-in-15-minutes/",
    "title": "How I built my first memory palace in 15 minutes",
    "description": "And you can too.",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2017-07-29",
    "categories": [
      "this happened to me"
    ],
    "contents": "\nI’m just like you. First, I have no special memory. Second, I have doubts about its usefulness in today’s world. So, what’s the reason I did it? To see if I can. And the time used wasn’t too big of a cost — fifteen minutes — for 16 items on an imaginary to-do list.\n“Get out. I need to go to my mind palace.” — Sherlock (and me before taking a nap). Image credit.For the past few days, I’ve been reading Joshua Foer’s book Moonwalking with Einstein: The Art and Science of Remembering Everything. The book describes the author’s one-year path on becoming the USA Memory Champion. During his first step into the craft of memory (also called mnemonics) he built a simple memory palace. Following his instructions I also built mine. That’s how I did it.\nOur memories are from prehistorical times.\nOur memories weren’t shaped in the environment like today’s. Hunter-gatherers didn’t need to remember all these abstract definitions from school. But they did have to remember where to find food, how to get home from the hunt, which plants and animals are dangerous — spatial and visual things.\nWe can describe why our memories sometimes work exceptionally well and other times badly Baker/baker paradox. In this study, researchers have figured out that it’s easier to remember baker (the profession) than Baker (the surname). That’s because baker creates way more associations (white clothes and a hat, bread, oven, nice smell) than the Baker surname, which only creates a connection (usually too weak to recall it) to the person’s face. Joshua described a trick to better memorization in his TEDx talk:\n\n“The entire art of what is going on in these memory contests, and the entire art of remembering stuff better in everyday life, is figuring out ways to transform capital B Bakers into lower-case B bakers — to take information that is lacking in context, in significance, in meaning, and transform it in some way, so that it becomes meaningful in the light of all the other things that you have in your mind.”\n\nThe goal of a memory palace is to translate whatever you have to remember in colorful, vivid, attention-grabbing images or scenes which you put on the familiar route. The first time that’s usually the route trough your home.\nExcuse me, Sherlock. I think you forgot the memory palace on your head. (Image credit.)My imaginary to-do list is almost the same as the one from the book. It has some changes during the author’s building of the palace because sometimes it wasn’t clear to me which items he wants to memorize.\nThe items on my list are pickled garlic, cottage cheese, Claudia Schiffer, salmon, 6 bottles of white wine, 3 pairs of socks, 3 hula-hoops, snorkel, ice, e-mail to Sophie, catsuit, Paul Newman, elk, dictaphone, rope, barometer.\nThat’s how I put them into my memory palace.\nMy house has never been so fun before.\nMy memory palace is my parents’ house. I start on the backyard, right beside the mailbox. I check the mail and find a glass of pickled garlic. Instead of the main door, there’s a box of cottage cheese. I pull it out, open it, and find Claudia Schiffer sunbathing in there. Next, I walk into the garage. There’s huge half alive salmon lying on the table. Then six bottles of white wine stand in the pantry. (Foer advises to spice them up with different personalities, that way they are easier to memorize.) Three pairs of (smelly) socks are getting dry hanging on the bicycle in the next room. When I walk to the next floor, there are three ladies hula-hooping on the stairs. Of course, I made them look hot, so they stick in the memory easier. In the kitchen, my brother is trying to dive in the sink. I block his snorkel and laugh at him when he goes out of breath. I open the freezer and a mountain of ice cubes falls down on me. On the window shelf, there is a book Sophie’s World with the phone on the top of it; send an e-mail to Sophie. On the first shelf, there’s a dancing lady (again hot) in a catsuit. On the television, there’s man inside the shopping bag so he’s supposed to be a new man: Paul Newman (You can do better than this.). There’s an elk on the second shelf. My father is marching on the tea table and shouting to the dictaphone. A climber is using a rope to climb on the picture hanging on the wall. Finally, I come to the thermometer but there is a bar in front of it, so it’s actually barometer.\n\nIt doesn’t seem so hard, huh? What are you waiting for?\n\nRemembering numbers is not so easy — but also not so hard.\nWords describing physical objects, like items on a shopping list, are easiest to put into the context — therefore, to remember. Way harder are abstract notions. How to put a complex verse of, for example, Shakespeare, into the memory palace? There’s no easy straightforward answer. However, there are some well-established systems for remembering numbers.\nThe elementary one is called Major System which “is based on the substitution of digits with sounds”. Those sounds combine into images for the memory palace. For example, if 0 is ‘s’ and 2 is ’n’, we can combine those two numbers into a ‘sun’ (vowels are ignored).\nThe most known more advanced system is Person-Action-Object (PAO). You pick and remember a person performing an action on an object for every two digit number. Let’s say your number is 123456. Then you combine the image from the person from 12, action from 34 and object from 56. One image, 6 digits — powerful. The same system can also be applied to remember the deck of cards.\nThe act of remembering is not as bad as you remember.\nI’ve always hated learning by root. It was my biggest nightmare when I had to recite — and before that, memorize by brute force — a poem at school. But building the memory palace feels different, it’s like creating something. Like creation through meditation.\nJoshua described the process in almost the same way:\n\n“I found that this was shockingly fun. I would never have expected that. It was fun because this is actually not about training your memory. What you’re doing, is you’re trying to get better and better at creating, at dreaming up, these utterly ludicrous, raunchy, hilarious, and hopefully unforgettable images in your mind’s eye.”\n\nMemorize; why? Why not?\nWhy memorize things? I think the right question is: why not? All great people in Antique had amazing memories, so it doesn’t hurt for sure. You need knowledge in order to obtain more knowledge — to connect the dots. Does it improve your life? Maybe. But it certainly makes it more interesting — therefore, memorable.\n\n“Monotony collapses time; novelty unfolds it. You can exercise daily and eat healthily and live a long life, while experiencing a short one. If you spend your life sitting in a cubicle and passing papers, one day is bound to blend unmemorably into the next — and disappear. That’s why it’s so important to change routines regularly, and take vacations to exotic locales, and have as many new experiences as possible that can serve to anchor our memories. Creating new memories stretches out psychological time, and lengthens our perception of our lives.” — Joshua Foer\n\nLive the life worth remembering; it will feel longer.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nOriginally published at thriveglobal.com.\n\n\n\n",
    "preview": "posts/2020-03-26-how-i-built-my-first-memory-palace-in-15-minutes/../../images/memory_palace_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-26-my-phone-use-in-numbers-and-graphs/",
    "title": "My phone use in numbers and graphs",
    "description": "Insights and visualizations from Moment app data",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2017-05-13",
    "categories": [
      "data science"
    ],
    "contents": "\nImage credit.For the last few months I’ve been interested in the attention economy, how modern technologies hijack our minds to make more profit. I also wrote a ten-page article on the topic as a part of my faculty subject’s grade. During the research, I came across the movement called Time Well Spent which wants to “transform the race for attention so it aligns with our best interests”. Their website also offers apps which help you save time instead of wasting it. One of them is Moment.\nMoment app.Moment app\nMoment is an app that automatically tracks and helps you manage time spent on the mobile phone. The free version of Moment displays the duration of your mobile usage per day. The paid version helps you fight and limit use. There is also a family version.\nIt has the option to export GPS location (latitude and longitude), date, time, and duration of sessions. I used this data to make an analysis presented in the following paragraphs.\nOverview\nI started using Moment in the early days of December and forgot about it until recently. Of course, the app was working on its own. The graph below presents my mobile use per day and location. I calculated the location as weighted average of latitudes and longitudes. Let me remind you that you can click on the image or hyperlinks below the graphs for interactive plots.\nSee the interactive plot.A recent study showed that young adults use their phones for a little more than 5 hours and check it 85 times per day on average. Let’s compare this to my results. I’ve been using it on average for 3 hours and 10 minutes and checked it 60 times each day. And I still have a feeling that I’m wasting my time on it…\nAverage day\nThat’s how my average day, expressed in probabilities of me being on the phone for each minute, looks like.\nSee the interactive plot.Probabilities over every minute are really noisy, so I applied the median filter to reduce noise. Unfortunately, because of my ‘free’ lifestyle (remember, I was on Erasmus exchange), you can’t learn a lot from the plot.\nAverage session\nIt’s time to take a closer look at the sessions — their durations — and compare them with the results of the previously mentioned study.\nSee the interactive plot.My median session is 95 seconds long. Theirs, less than half a minute. I assume that’s due to the two reasons: * I usually turn off the mobile data or wifi. Consequently, every time I want to check something online I have to turn it on again and that takes some time. * I mostly don’t use push notifications. That takes additional time when I want to check social media notifications — especially if I get hooked in the never-ending news feed.\nFavorite locations\nYou can be gain a lot more than just phone usage from your mobile data. For example, favorite locations (for using my phone). I limited those to Gdansk and decided to cluster them to make top seven. Markers area is proportional to the time spent on the mobile phone on the exact location.\nMy top 7 places (for using phone) in Gdansk.\nBiggest marker (93 hours) represents my home during the exchange. The dot above it, my university. Marker on the right, beautiful old town. Sopot, a place for parties…\nCoding and writing\nI wanted to keep this post as short and as interesting as possible— without going too much into detail (the article is meant for the general public). Let numbers and graphs speak for themselves. The initial plan also included t-tests to compare use with and without specific social media apps and distribution for my waking time. In the end, for the reasons mentioned above, I decided to leave them out.\nI implemented the code in Python programming language using Jupyter Notebook. For data visualization (excluding the map), I used plotly.\n\n\n\n",
    "preview": "posts/2020-03-26-my-phone-use-in-numbers-and-graphs/../../images/phone_numbers_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-26-monument-to-erasmus/",
    "title": "Monument to Erasmus",
    "description": "No description needed.",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2017-03-01",
    "categories": [
      "this happened to me"
    ],
    "contents": "\nI decided not to ask anyone to correct grammar errors in my writing. I (or we, Erasmus people) have been talking this way all the semester. If it was good enough for us to build great friendships, it will be also good enough to read a few sentences.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nIt’s 8th February1, first day of the last days of my Erasmus in Gdansk. Yesterday I passed all my faculty obligations. Previous years, that would uplift me. Nowadays I feel empty. Like I’m waiting for my best time of life just to pass by. Like I’m waiting for my adulthood to arrive.\nI remember one night in the last days of November, trying to fall asleep2, thinking: “Erasmus is so amazing, I don’t want to fall asleep.” And then calculating that I’m almost on half of my exchange. Time, why do you have to pass so fast? Take it easy, pretend you are also on Erasmus.\nSo here I am, acknowledging my experience. Building (writing) it the monument and at the same time trying to escape (or at least postpone) post Erasmus depression. Using depression as an inspiration and writing as a medicine for it.\nBut, what exactly made me, emotionally reserved person3, feel so depressed at the end and uplifted during the exchange? My friends would guess: partying. It’s true that I’ve never been partying so much in one semester. But I don’t think the reason are parties. My best memories of Erasmus don’t include any (hardcore) parties.4 It’s also not travelling as my acquaintances think. Although I’ve never travelled so much before. Sometimes I even cancelled some of my travel plans because I had so much fun at my city. (Naïve) elders think it’s because of the classes and university. No further explanation needed.5\nIt’s not even about saying yes6 to all new opportunities. Saying yes to one — to go on Erasmus — is enough.7 And when opportunities say yes to you, then you know you are on Erasmus. You have no other choice than to go with the flow, you are far away from your home and friends. There’s no place to hide. You are pushed out of your comfort zone and that’s where the magic happens. It feels like being a child again, discovering the whole new world. New world, where connecting and being present is the biggest present you can give and get.\nErasmus is about making family who lives all around the Europe.\nIt’s 28th of February. I’m already home. My Erasmus days already passed, but memories stayed. Dear Erasmus friends, thank you for making these memories with me. Listening to Oroscopo, singing correctly only “tutta la notte” part, I salute you with my spinach smoothie.\n\nIronically, also Slovenian national day of culture. Prešeren, let me make you proud.↩︎\nOr, better said, wake up.↩︎\nThat’s what she said.↩︎\nThe reason for that isn’t too much alcohol consumption.↩︎\nFurther explanation: Actually, I liked my (lack of) classes. I had way more freedom to pick interesting ones compared to my home university.↩︎\nSome ‘ragazzi’ would prefer: “Yes. Maybe.”↩︎\nLet me give you an (street smart) advice when deciding about Erasmus. Not from the book, but from the shoe: »Just do it.«↩︎\n",
    "preview": "posts/2020-03-26-monument-to-erasmus/../../images/erasmus_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  },
  {
    "path": "posts/2020-03-28-the-role-of-luck-in-poker/",
    "title": "The role of luck in poker",
    "description": "How the number of hands played affects the variance?",
    "author": [
      {
        "name": "Miha Gazvoda",
        "url": "https://mihagazvoda.com"
      }
    ],
    "date": "2015-09-14",
    "categories": [
      "data science",
      "decision making under uncertainty"
    ],
    "contents": "\nImage credit.What makes poker the most thrilling and painful at the same time? Variance. Everyone can be a winner. But for how long?\n\n\\(\\bullet\\bullet\\bullet\\)\n\nA few months ago me and my poker buddies had the debate: ‘What happens with the variance over the increasing hand sample?’ The answer was obvious to everybody, but surprisingly — different. Everyone’s arguments, reasoning, and logic seemed legit. But statistics can be tricky and sometimes, just like in poker, your ‘feeling’ is not enough. So I, the nerdiest guy in the group, decided to show off.\nBasics\n“Half of the answer lies within a well constructed question,” a wise man once said. If I’m the first to say it, then I’m that wise man. So, let’s break it down. First, the definition of variance: ‘Variance is a number which measures how far a set of numbers is spread out around mean.’ A more useful term is standard deviation which is the square root of the variance. Both represent how swingy your poker results are. But the standard deviation can tell you something more. Let’s get right to a poker example. A hero plays 0 expected value (EV) game with a standard deviation of 100 big blinds per 100 hands (usual standard deviation for no limit Texas hold’ em 6-player cash games). His level of the skill (0 EV) will stay the same through the whole post. Because of this exact standard deviation, there is 68% chance his bankroll will change less than 100 big blinds after 100 hands. But what would happen if the hero played a different number of hands?\nVariance of winnings\nLet’s start with the obvious one, the variance of winnings. It tells you how much swings you can expect in big blinds or moneywise. But, does it get smaller or bigger with more hands played? Think for yourself but be careful. Your peasant logic can get outplayed by the lady variance. And this time you can’t blame her.\nHere are seven different simulated graphs of the hero’s winnings trough 100k hand sample. To make those graphs more understandable you can think about them as graphs of players with the exact same skill level.\nGraph 1It’s kind of hard to believe, those are all simulated graphs of 0 EV player. As you can see, lines are getting more and more dispersed. That means a bigger variance and also standard deviation. If you still have thoughts such as “luck will cancel out at the end of the day”, let me show you another graph. Let’s say the hero plays 1k hands and at the end of a hand sample, he makes a dot of his winnings. Then he goes from scratch again and makes 2k hands. Dot again. Then 3k hands, 4k, 5k… So on, until the 1M hands. Here is what he gets:\nGraph 2One more time, it gets dispersed. To make things clear, I even displayed a standard deviation line of the winnings. It’s proportional to the square root of a number of hands. The equation for standard deviation is equal to\n\\(std_{winnings} = K \\sqrt(hands)\\)\nIn our case, K is equal to 10.1 For example, if your standard deviation is 85bbs/100hands, the value of K would be 8.5. You can actually calculate a few interesting and useful information from the equation above. You can see that any fixed hand sample has the same standard deviation no matter where on the graph it is located.\nThose results are somewhat hard to understand at first sight so let’s bring a few examples, which make ‘logical’ sense:\nYou can’t win more than one stack in a single hand. If you play more hands, there is a possibility to win more. That tiny portions add to dispersion.\nLet’s say you roll a ball in a straight line on the concrete which is not completely flat and has some sand on it. The ball will eventually go out of the line. The longer line it makes, there is the higher chance it will be farther away from the initial line. The last graph represents this situation from bird’s eye perspective.\nBefore you start playing as little as possible to lower your variance, read on.\nVariance of a win rate\nThis case turns around the whole picture. Win rate is defined as big blinds won divided by a number of hands played. Considering this we get a bit different standard deviation’s equation:\n\\(std_{winrate} = \\frac{100*K}{hands}\\)\nActually, something has dramatically changed. The standard deviation now gets smaller trough the increasing hand sample. Let’s just divide the winnings with a number of hands/100 and here is what we get from Graph 1:\nGraph 3Win rates are getting closer to 0 bb/100hands, which is hero’s genuine win rate. Same thing for Graph 2:\nGraph 4Obviously, the more hands you play, the more accurate your win rate should become. Using the second equation we can calculate how many hands you need to lower your standard deviation to 1 bb/100hands. That means, if your win rate is 1bb/100hands, you can be 67% sure your win rate is somewhere between 0 and 2 bb/100hands. And for that, you need 1 million hands. So grind on…\nConclusion\nUnderstanding variance is one of the key factors of becoming a good poker player, especially because of your mental game. You should expect sick things to happen and be capable of facing them. Don’t get too much into those poker software lines. They aren’t as good predictor of your skill as you may think, even the EV line. Just remember — never underestimate the variance and overestimate your poker skill. I wish you all the best at the poker tables.\n\n\\(\\bullet\\bullet\\bullet\\)\n\nAbout the author\nMiha Gazvoda was a poker player who blamed the variance for not making it as a pro. Nevertheless, he luckily had enough skill to become Slovenian poker champion in year 2014.\nOriginally published at www.pokerstrategy.com on September 14, 2015.\n\nWhere do we get 10? The standard deviation should be 100 per 100 hands. So just insert this in equation you get. 100 = K*sqrt(100). K should be 10. K also represents standard deviation for 1 hand.↩︎\n",
    "preview": "posts/2020-03-28-the-role-of-luck-in-poker/../../images/role_luck_in_poker_preview.png",
    "last_modified": "2021-01-25T20:19:26+01:00",
    "input_file": {},
    "preview_width": 1872,
    "preview_height": 1404
  }
]
